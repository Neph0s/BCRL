import json
import requests
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from utils import get_response, save_result, save_result_txt


# é…ç½®æ–¹æ³•é€‰æ‹©
search_model = 'gemini_search'  # é€‰æ‹© 'gemini_search' æˆ– 'deer-flow'
question_model = 'gpt' #'claude-4-sonnet'

def process_entity(entity):
    """å¤„ç†å•ä¸ªå®ä½“çš„å‡½æ•°ï¼Œç”¨äºå¹¶å‘æ‰§è¡Œ"""
    print(f"å¼€å§‹æŸ¥è¯¢å®ä½“: {entity} (ä½¿ç”¨æ–¹æ³•: {search_model})")
    
    result = {'entity': entity} 
    
    from prompts import search_prompt, search_second_prompt,  question_generate_prompt

    messages = []

    # æœé›†å®ä½“ä¿¡æ¯
    prompt = search_prompt.replace('{entity}', entity)
    messages.append({'role': 'user', 'content': prompt})
    knowledge = get_response(model=search_model, messages=messages)
    result['search_response'] = knowledge
    messages.append({'role': 'assistant', 'content': knowledge})

    # äºŒæ¬¡æ‰©å±•
    messages.append({'role': 'user', 'content': search_second_prompt})
    knowledge2 = get_response(model=search_model, messages=messages)
    result['search_again_response'] = knowledge2
    messages.append({'role': 'assistant', 'content': knowledge2})

    import pdb; pdb.set_trace()

    
    # ç”Ÿæˆé—®é¢˜
    for N_I_LOW, N_I_HIGH in [(3, 4), (5, 6)]:
        prompt = question_generate_prompt.replace('{entity}', entity).replace('{N_I_LOW}', str(N_I_LOW)).replace('{N_I_HIGH}', str(N_I_HIGH)).replace('{N_Q}', '3')
        messages.append({'role': 'user', 'content': prompt})
        response = get_response(model=question_model, messages=messages)

        if 'question_response' not in result:
            result['question_response'] = response
        else:
            result['question_response']['questions'] += response['questions']

    return result


parallel = False

def main():
    entities = ["é˜¿è’™ï¼ˆè¯¡ç§˜ä¹‹ä¸»ï¼‰", "åœŸä¼¯ï¼ˆç‰§ç¥è®°ï¼‰", "ä¸¹å¦®è‰ä¸Â·å¦æ ¼åˆ©å®‰ï¼ˆå†°ä¸ç«ä¹‹æ­Œï¼‰", "èŠ™å®å¨œï¼ˆåŸç¥ï¼‰", "é›ªç‹ï¼ˆèœœé›ªå†°åŸçš„å‰ç¥¥ç‰©ï¼‰", "è¿›æ‰ä¸­å­¦ï¼ˆä¸Šæµ·ï¼‰", "Kano (é¹¿ä¹ƒ)", "Hamlet (character)", "Kyogre", "Sam Altman", "Ryner Lute", "Airi Tazume"]

    # æ ¹æ®æ–¹æ³•è°ƒæ•´å¹¶å‘æ•°
    
    results = {entity: None for entity in entities}

    if parallel:
        max_workers = 5 if search_model == 'gemini_search' else 1  # 
        print(f"æœ€å¤§å¹¶å‘æ•°: {max_workers}")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_entity = {executor.submit(process_entity, entity): entity for entity in entities}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_entity):
                entity = future_to_entity[future]
                result = future.result()
                results[entity] = result

    else:
        for entity in entities:
            result = process_entity(entity)
            results[entity] = result

    completed = len([result for result in results.values() if result is not None])
    failed = len(entities) - completed
    
    print(f"âœ… æˆåŠŸ: {completed}, âŒ å¤±è´¥: {failed}")

    # ä¿å­˜æ±‡æ€»ç»“æœ
    os.makedirs("results", exist_ok=True)
    with open(f'results/{search_model}.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # ä¿å­˜TXTæ ¼å¼çš„ç®€åŒ–ç»“æœ
    save_result_txt(f'results/{search_model}_simple.txt', results)

    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨ results/ ç›®å½•ä¸‹ï¼ˆä½¿ç”¨{search_model}æ–¹æ³•ï¼‰")
    print(f"ğŸ“„ JSONæ ¼å¼: results/{search_model}.json")
    print(f"ğŸ“„ TXTæ ¼å¼: results/{search_model}_simple.txt")

if __name__ == "__main__":
    main()