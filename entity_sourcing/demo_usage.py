#!/usr/bin/env python3
"""
ä½¿ç”¨ç¤ºèŒƒï¼šé«˜æ•ˆéšæœºé‡‡æ ·ä¸æŒ‡å®šç±»åˆ«çš„å®ä½“
æ¼”ç¤ºå¦‚ä½•è·å–50ä¸ªéšæœºä¸­æ–‡å®ä½“
"""

from entity_collector import WikidataEntityCollector

def demo_random_sampling():
    """ç¤ºèŒƒéšæœºé‡‡æ ·åŠŸèƒ½"""
    print("ç¤ºèŒƒï¼šé«˜æ•ˆéšæœºé‡‡æ ·ä¸æŒ‡å®šç±»åˆ«çš„å®ä½“")
    print("=" * 60)
    
    # åˆ›å»ºä¸­æ–‡æ”¶é›†å™¨
    print("1. åˆå§‹åŒ–ä¸­æ–‡å®ä½“æ”¶é›†å™¨...")
    collector = WikidataEntityCollector(language='zh', qrank_csv_file='qrank.csv')
    
    # è®¾ç½®éšæœºé‡‡æ ·
    print("2. è®¾ç½®éšæœºé‡‡æ ·ï¼ˆä¸æŒ‡å®šç±»åˆ«ï¼‰...")
    sample_size = 50
    
    # ä½¿ç”¨Noneè§¦å‘éšæœºé‡‡æ ·
    print(f"3. å¼€å§‹éšæœºé‡‡æ ·{sample_size}ä¸ªä¸­æ–‡å®ä½“...")
    mixed_categories = [("éšæœºé‡‡æ ·å®ä½“", None)]
    
    df = collector.collect_entities(mixed_categories, limit_per_category=sample_size)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"\nâœ“ æˆåŠŸé‡‡æ ·åˆ° {len(df)} ä¸ªéšæœºä¸­æ–‡å®ä½“")
    
    if not df.empty:
        print("\nğŸ“‹ éšæœºé‡‡æ ·çš„ä¸­æ–‡å®ä½“åˆ—è¡¨ï¼š")
        print("-" * 90)
        
        for i, (_, entity) in enumerate(df.iterrows(), 1):
            score = entity['popularity_score']
            popular = "ğŸ”¥çŸ¥å" if entity['is_popular'] else "ğŸ¤«ä¸çŸ¥å"
            sampled_from = entity.get('sampled_from', 'æœªçŸ¥ç±»å‹')
            desc = entity.get('description', '')
            desc_short = desc[:40] + '...' if len(desc) > 40 else desc
            
            print(f"{i:2d}. {entity['label']:<25} ({entity['id']}) - {score:>10,.0f} {popular} [{sampled_from}]")
            if desc_short:
                print(f"    {desc_short}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š é‡‡æ ·ç»Ÿè®¡ï¼š")
        total = len(df)
        with_scores = len(df[df['popularity_score'] > 0])
        popular = len(df[df['is_popular'] == True])
        
        print(f"   æ€»å®ä½“æ•°ï¼š{total}")
        print(f"   æœ‰çŸ¥ååº¦è¯„åˆ†ï¼š{with_scores} ({with_scores/total*100:.1f}%)")
        print(f"   çŸ¥åå®ä½“ï¼š{popular}")
        print(f"   ä¸çŸ¥åå®ä½“ï¼š{total - popular}")
        
        # æŒ‰é‡‡æ ·æ¥æºç»Ÿè®¡
        if 'sampled_from' in df.columns:
            print(f"\nğŸ¯ æŒ‰é‡‡æ ·æ¥æºç»Ÿè®¡ï¼š")
            source_counts = df['sampled_from'].value_counts()
            for source, count in source_counts.items():
                source_df = df[df['sampled_from'] == source]
                avg_score = source_df['popularity_score'].mean()
                print(f"   {source}: {count}ä¸ª (å¹³å‡çŸ¥ååº¦: {avg_score:,.0f})")
        
        # çŸ¥ååº¦åˆ†å¸ƒ
        print(f"\nğŸ“ˆ çŸ¥ååº¦åˆ†å¸ƒï¼š")
        zero_score = len(df[df['popularity_score'] == 0])
        low_score = len(df[(df['popularity_score'] > 0) & (df['popularity_score'] <= 10000)])
        mid_score = len(df[(df['popularity_score'] > 10000) & (df['popularity_score'] <= 100000)])
        high_score = len(df[df['popularity_score'] > 100000])
        
        print(f"   æ— è¯„åˆ† (=0): {zero_score}ä¸ª")
        print(f"   ä½çŸ¥ååº¦ (1-10K): {low_score}ä¸ª")
        print(f"   ä¸­çŸ¥ååº¦ (10K-100K): {mid_score}ä¸ª")
        print(f"   é«˜çŸ¥ååº¦ (>100K): {high_score}ä¸ª")
        
        # ä¿å­˜ç»“æœ
        filename = f"random_sampled_entities_{sample_size}.csv"
        df.to_csv(filename, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°ï¼š{filename}")
        
        # æ˜¾ç¤ºæå€¼
        if with_scores > 0:
            print("\nğŸ† æœ€çŸ¥åå®ä½“TOP3ï¼š")
            top_entities = df[df['popularity_score'] > 0].nlargest(3, 'popularity_score')
            for _, entity in top_entities.iterrows():
                score = entity['popularity_score']
                source = entity.get('sampled_from', 'æœªçŸ¥')
                print(f"   - {entity['label']} ({source}): {score:,.0f}")
        
        if zero_score > 0:
            print(f"\nğŸ¤« æ— çŸ¥ååº¦æ•°æ®çš„å®ä½“ç¤ºä¾‹ï¼š")
            zero_entities = df[df['popularity_score'] == 0].head(3)
            for _, entity in zero_entities.iterrows():
                source = entity.get('sampled_from', 'æœªçŸ¥')
                print(f"   - {entity['label']} ({source})")
        
        print(f"\nğŸ”¬ éšæœºé‡‡æ ·æ•°æ®é›†çš„åº”ç”¨ä»·å€¼ï¼š")
        print("   âœ“ è·¨é¢†åŸŸå®ä½“è¡¨ç¤ºå­¦ä¹ ")
        print("   âœ“ çŸ¥è¯†å›¾è°±éšæœºæ¸¸èµ°ç®—æ³•æµ‹è¯•")
        print("   âœ“ å®ä½“å¤šæ ·æ€§å’Œè¦†ç›–åº¦åˆ†æ")
        print("   âœ“ é•¿å°¾å®ä½“å‘ç°å’Œç ”ç©¶")
        print("   âœ“ æ— åé‡‡æ ·åŸºå‡†æ•°æ®é›†æ„å»º")
        
        # é‡‡æ ·è´¨é‡è¯„ä¼°
        sample_types = ["cities", "books", "films", "companies", "fictional characters", 
                       "songs", "universities", "museums", "musical groups", "TV series",
                       "video games", "albums", "artworks", "festivals", "awards"]
        diversity_score = len(source_counts) / len(sample_types) if 'sampled_from' in df.columns else 0
        coverage_score = with_scores / total
        
        print(f"\nğŸ“ é‡‡æ ·è´¨é‡è¯„ä¼°ï¼š")
        print(f"   ç±»å‹å¤šæ ·æ€§: {diversity_score:.2f} ({len(source_counts) if 'sampled_from' in df.columns else 0}/{15}ä¸ªç±»å‹)")
        print(f"   æ•°æ®è¦†ç›–åº¦: {coverage_score:.2f} ({with_scores}/{total}æœ‰è¯„åˆ†)")
        
    else:
        print("âŒ æœªèƒ½é‡‡æ ·åˆ°ä»»ä½•å®ä½“")
    
    print("\n" + "=" * 60)
    print("éšæœºé‡‡æ ·ç¤ºèŒƒå®Œæˆï¼")

if __name__ == "__main__":
    demo_random_sampling()